FANN_FIX_2.0
decimal_point=8
num_layers=5
learning_rate=0.250000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=3
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=90
cascade_candidate_limit=256000
cascade_weight_multiplier=102
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=64 128 192 256 
layer_sizes=2 9 17 3 2 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0) (0, 0, 0) (2, 14, 256) (2, 14, 256) (2, 14, 256) (2, 14, 256) (2, 14, 256) (2, 14, 256) (2, 14, 256) (2, 14, 256) (0, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (9, 14, 256) (0, 14, 256) (17, 14, 256) (17, 14, 256) (0, 14, 256) (3, 14, 256) (0, 14, 256) 
connections (connected_to_neuron, weight)=(0, 384000) (1, -89817) (0, 384000) (1, -301435) (0, 384000) (1, -381632) (0, 384000) (1, -353922) (0, 384000) (1, -307860) (0, 384000) (1, -308605) (0, 384000) (1, -290633) (0, 384000) (1, -247182) (2, -80537) (3, -105360) (4, -148217) (5, -145899) (6, 135779) (7, 135779) (8, -105455) (9, -29694) (10, -331433) (2, 4944) (3, -28776) (4, 30730) (5, 31872) (6, 31872) (7, 31872) (8, -28776) (9, 3652) (10, -275132) (2, 145330) (3, -35416) (4, 158711) (5, 158711) (6, -32823) (7, -33421) (8, -34985) (9, 144878) (10, -330123) (2, 44946) (3, 54615) (4, 62620) (5, 62620) (6, -51572) (7, -51580) (8, 54629) (9, 44011) (10, -330548) (2, 73811) (3, 120264) (4, 81827) (5, 90411) (6, -118927) (7, -118927) (8, 120285) (9, 73018) (10, -316561) (2, -89624) (3, 63982) (4, -65262) (5, -211904) (6, 3028) (7, -3744) (8, 62151) (9, 39736) (10, 354885) (2, 5954) (3, -29805) (4, 32190) (5, 32766) (6, 32919) (7, 32919) (8, -29805) (9, 4660) (10, -275024) (2, 65946) (3, 110984) (4, 82973) (5, 82973) (6, -100198) (7, -100710) (8, 110990) (9, 65133) (10, -314871) (2, 198076) (3, -281969) (4, 285648) (5, 282986) (6, -101185) (7, -101180) (8, -281969) (9, -116625) (10, 379927) (2, 52513) (3, -78040) (4, 80861) (5, 80300) (6, 80861) (7, 80861) (8, -78040) (9, 51115) (10, -267267) (2, 104483) (3, -155341) (4, 145869) (5, 321123) (6, -275359) (7, -275274) (8, -155263) (9, -250069) (10, -300786) (2, -73317) (3, 76551) (4, -363939) (5, -363939) (6, -64100) (7, -64100) (8, 82542) (9, -73668) (10, -340847) (2, -125914) (3, -122995) (4, 105723) (5, -55645) (6, 39120) (7, 47624) (8, -146988) (9, -32968) (10, 328463) (2, 303028) (3, -373194) (4, 373241) (5, 373310) (6, -302828) (7, -302336) (8, -373194) (9, -299626) (10, 342237) (2, 132719) (3, -363252) (4, 363096) (5, 347527) (6, -173622) (7, -173489) (8, -363252) (9, -216785) (10, 377696) (2, -123722) (3, -318331) (4, 313230) (5, 320398) (6, -331375) (7, -331375) (8, -318331) (9, -325756) (10, 135382) (11, 29476) (12, 58139) (13, 29548) (14, 41285) (15, 35541) (16, -17707) (17, 58273) (18, 36580) (19, -2323) (20, 63045) (21, -5370) (22, 21320) (23, -29391) (24, -1903) (25, -4042) (26, -13243) (27, -120034) (11, 27200) (12, 28364) (13, 16571) (14, 29222) (15, 12216) (16, 21411) (17, 24923) (18, 6588) (19, 16244) (20, 21378) (21, 26547) (22, 21074) (23, 2164) (24, 1655) (25, 18297) (26, 431) (27, -11883) (28, 17441) (29, 506) (30, 2371) 
